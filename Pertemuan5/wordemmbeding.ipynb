{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd1560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c453f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"article_text\": [\n",
    "        \"information retrieval is the process of obtaining information\",\n",
    "        \"text mining and information retrieval are related fields\",\n",
    "        \"search engine uses information retrieval techniques\",\n",
    "        \"word embedding represents words as vectors\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acf1c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [information, retrieval, is, the, process, of,...\n",
       "1    [text, mining, and, information, retrieval, ar...\n",
       "2    [search, engine, uses, information, retrieval,...\n",
       "3    [word, embedding, represents, words, as, vectors]\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()                     # lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)    # hapus simbol\n",
    "    tokens = text.split()                   # tokenisasi\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['article_text'].apply(preprocess)\n",
    "df['tokens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fe1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=df['tokens'],\n",
    "    vector_size=100,   # ukuran vektor\n",
    "    window=5,          # konteks window\n",
    "    min_count=1,       # minimal kemunculan kata\n",
    "    workers=4,\n",
    "    sg=1               # 1 = Skip-gram, 0 = CBOW\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa313752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.3659163e-04  2.3666486e-04  5.1044468e-03  9.0084802e-03\n",
      " -9.3049398e-03 -7.1182284e-03  6.4604352e-03  8.9744320e-03\n",
      " -5.0162170e-03 -3.7635425e-03  7.3826737e-03 -1.5332866e-03\n",
      " -4.5394995e-03  6.5539097e-03 -4.8626214e-03 -1.8159528e-03\n",
      "  2.8788224e-03  9.9110615e-04 -8.2872696e-03 -9.4514471e-03\n",
      "  7.3134988e-03  5.0708596e-03  6.7612301e-03  7.6123292e-04\n",
      "  6.3512716e-03 -3.4058816e-03 -9.4598409e-04  5.7686744e-03\n",
      " -7.5229313e-03 -3.9362879e-03 -7.5127580e-03 -9.2994922e-04\n",
      "  9.5410654e-03 -7.3208390e-03 -2.3343961e-03 -1.9397155e-03\n",
      "  8.0780759e-03 -5.9321634e-03  4.5860106e-05 -4.7556497e-03\n",
      " -9.6061369e-03  5.0088447e-03 -8.7593012e-03 -4.3927436e-03\n",
      " -3.4098714e-05 -2.9472820e-04 -7.6625361e-03  9.6169394e-03\n",
      "  4.9831397e-03  9.2354324e-03 -8.1610726e-03  4.4982596e-03\n",
      " -4.1370410e-03  8.2379940e-04  8.5003525e-03 -4.4652107e-03\n",
      "  4.5191231e-03 -6.7871823e-03 -3.5488161e-03  9.4014416e-03\n",
      " -1.5770510e-03  3.2055390e-04 -4.1423207e-03 -7.6836897e-03\n",
      " -1.5076330e-03  2.4693415e-03 -8.8757038e-04  5.5352408e-03\n",
      " -2.7434081e-03  2.2602635e-03  5.4567498e-03  8.3471173e-03\n",
      " -1.4531912e-03 -9.2093665e-03  4.3715807e-03  5.7007006e-04\n",
      "  7.4447277e-03 -8.1388350e-04 -2.6383128e-03 -8.7554893e-03\n",
      " -8.5554383e-04  2.8264883e-03  5.4018660e-03  7.0547382e-03\n",
      " -5.7031144e-03  1.8578789e-03  6.0896720e-03 -4.7986512e-03\n",
      " -3.1085764e-03  6.7977062e-03  1.6327528e-03  1.9023729e-04\n",
      "  3.4755163e-03  2.1680557e-04  9.6196868e-03  5.0625382e-03\n",
      " -8.9193610e-03 -7.0424811e-03  9.0196927e-04  6.3938601e-03]\n",
      "Panjang vektor: 100\n"
     ]
    }
   ],
   "source": [
    "vector_ir = model.wv['information']\n",
    "print(vector_ir)\n",
    "print(\"Panjang vektor:\", len(vector_ir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893e0e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mining', 0.21881316602230072),\n",
       " ('uses', 0.21615716814994812),\n",
       " ('fields', 0.09310433268547058),\n",
       " ('word', 0.09298862516880035),\n",
       " ('process', 0.08406124264001846)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('information', topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eda2d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: -0.010850367\n"
     ]
    }
   ],
   "source": [
    "similarity = model.wv.similarity('information', 'retrieval')\n",
    "print(\"Similarity:\", similarity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
